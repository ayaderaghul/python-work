{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ac79223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Model loaded successfully\n",
      "Starting workplace safety monitoring...\n",
      "Press 'q' to quit\n",
      "Sun Jul 27 22:01:06 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 22:01:10 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 22:01:16 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 22:01:30 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 22:01:38 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 22:01:45 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 22:01:50 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 22:01:57 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 22:02:03 2025 - ALERT: Worker without helmet detected!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 139\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m person_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m tracked_persons \u001b[38;5;129;01mor\u001b[39;00m current_time - tracked_persons[person_id] > ALERT_COOLDOWN:\n\u001b[32m    138\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime.ctime()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - ALERT: Worker without helmet detected!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[43mwinsound\u001b[49m\u001b[43m.\u001b[49m\u001b[43mBeep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    140\u001b[39m     last_alert_time = current_time\n\u001b[32m    141\u001b[39m     tracked_persons[person_id] = current_time\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import winsound\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "ALERT_DURATION = 3  # seconds\n",
    "MIN_CONFIDENCE = 0.7  # Minimum confidence threshold\n",
    "ALERT_COOLDOWN = 5  # seconds between alerts\n",
    "ENTRANCE_REGION = (0, 0, 1280, 720)  # Camera view area\n",
    "\n",
    "# Initialize face detection (using Haar Cascade included with OpenCV)\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Initialize device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize ViT model with modern syntax\n",
    "try:\n",
    "    # Load with no weights (since you have custom trained weights)\n",
    "    model = vit_b_16(weights=None, num_classes=2)\n",
    "    \n",
    "    # Load your custom state_dict\n",
    "    state_dict = torch.load('my_vit_model.pth', map_location=device)\n",
    "    \n",
    "    # Adapt keys if needed\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        if k == 'heads.weight':\n",
    "            k = 'heads.head.weight'\n",
    "        elif k == 'heads.bias':\n",
    "            k = 'heads.head.bias'\n",
    "        new_state_dict[k] = v\n",
    "    \n",
    "    model.load_state_dict(new_state_dict)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    print(\"Model loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Define transforms using modern torchvision weights\n",
    "weights = ViT_B_16_Weights.DEFAULT  # This is just for the transform, not the weights\n",
    "transform = weights.transforms() if hasattr(weights, 'transforms') else transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "# Tracking variables\n",
    "last_alert_time = 0\n",
    "tracked_persons = {}\n",
    "\n",
    "def in_entrance_region(box):\n",
    "    x, y, w, h = box\n",
    "    center_x = x + w//2\n",
    "    center_y = y + h//2\n",
    "    return (ENTRANCE_REGION[0] < center_x < ENTRANCE_REGION[2] and \n",
    "            ENTRANCE_REGION[1] < center_y < ENTRANCE_REGION[3])\n",
    "\n",
    "print(\"Starting workplace safety monitoring...\")\n",
    "print(\"Press 'q' to quit\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error reading frame\")\n",
    "        break\n",
    "    \n",
    "    current_time = time.time()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE\n",
    "    )\n",
    "    \n",
    "    for (x, y, w, h) in faces:\n",
    "        if not in_entrance_region((x, y, w, h)):\n",
    "            continue\n",
    "            \n",
    "        # Expand to head region\n",
    "        head_y1 = max(0, y - int(h * 0.4))\n",
    "        head_y2 = min(frame.shape[0], y + h + int(h * 0.1))\n",
    "        head_x1 = max(0, x - int(w * 0.3))\n",
    "        head_x2 = min(frame.shape[1], x + w + int(w * 0.3))\n",
    "        \n",
    "        head_roi = frame[head_y1:head_y2, head_x1:head_x2]\n",
    "        if head_roi.size == 0:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Convert and preprocess\n",
    "            pil_img = Image.fromarray(cv2.cvtColor(head_roi, cv2.COLOR_BGR2RGB))\n",
    "            img_tensor = transform(pil_img).unsqueeze(0).to(device)\n",
    "            \n",
    "            # Predict\n",
    "            with torch.no_grad():\n",
    "                output = model(img_tensor)\n",
    "                probs = torch.softmax(output, dim=1)\n",
    "            \n",
    "            pred_class = torch.argmax(probs).item()\n",
    "            helmet_confidence = probs[0][pred_class].item()\n",
    "            \n",
    "            if helmet_confidence < MIN_CONFIDENCE:\n",
    "                continue\n",
    "                \n",
    "            # Visualization\n",
    "            person_id = f\"{x}_{y}\"\n",
    "            color = (0, 255, 0) if pred_class == 1 else (0, 0, 255)\n",
    "            label = \"HELMET\" if pred_class == 1 else \"NO HELMET!\"\n",
    "            \n",
    "            cv2.rectangle(frame, (head_x1, head_y1), (head_x2, head_y2), color, 2)\n",
    "            cv2.putText(frame, f\"{label} {helmet_confidence:.2f}\", \n",
    "                       (head_x1, head_y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "            \n",
    "            # Alert for no helmet\n",
    "            if pred_class == 0 and current_time - last_alert_time > ALERT_COOLDOWN:\n",
    "                if person_id not in tracked_persons or current_time - tracked_persons[person_id] > ALERT_COOLDOWN:\n",
    "                    print(f\"{time.ctime()} - ALERT: Worker without helmet detected!\")\n",
    "                    winsound.Beep(1000, 1000)\n",
    "                    last_alert_time = current_time\n",
    "                    tracked_persons[person_id] = current_time\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Processing error: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Draw monitoring zone\n",
    "    cv2.rectangle(frame, (ENTRANCE_REGION[0], ENTRANCE_REGION[1]), \n",
    "                 (ENTRANCE_REGION[2], ENTRANCE_REGION[3]), (255, 0, 0), 2)\n",
    "    cv2.putText(frame, \"Monitoring Zone\", (ENTRANCE_REGION[0]+10, ENTRANCE_REGION[1]+30), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "    \n",
    "    # Display\n",
    "    cv2.imshow('Workplace Safety Monitoring', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Monitoring stopped\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
