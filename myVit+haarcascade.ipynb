{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c6c3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacopo\\Documents\\python\\myenv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jacopo\\Documents\\python\\myenv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting workplace safety monitoring...\n",
      "Press 'q' to quit\n",
      "Sun Jul 27 21:08:00 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 21:08:03 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 21:08:14 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 21:08:21 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 21:08:29 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 21:08:36 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 21:08:43 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 21:08:52 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 21:08:55 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 21:09:00 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 21:09:06 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 21:09:12 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 21:09:20 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 21:09:26 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 21:09:31 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 21:09:36 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 21:09:44 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 21:09:48 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 21:09:53 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 21:09:59 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 21:10:05 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 21:10:11 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 21:10:16 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 21:10:24 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 21:10:29 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 21:10:36 2025 - ALERT: Worker without helmet detected!\n",
      "Sun Jul 27 21:10:43 2025 - ALERT: Worker without helmet detected!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import vit_b_16\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import winsound\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "ALERT_DURATION = 3  # seconds\n",
    "MIN_CONFIDENCE = 0.7  # Only consider detections above this confidence\n",
    "ALERT_COOLDOWN = 5  # seconds between alerts for same person\n",
    "ENTRANCE_REGION = (0, 0, 1280, 720)  # Define your camera's view area\n",
    "\n",
    "# Create directory for model files if not exists\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Download face detection model files if not present\n",
    "if not os.path.exists('models/haarcascade_frontalface_default.xml'):\n",
    "    print(\"Downloading face detection model...\")\n",
    "    import urllib.request\n",
    "    urllib.request.urlretrieve(\n",
    "        \"https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\",\n",
    "        \"models/haarcascade_frontalface_default.xml\"\n",
    "    )\n",
    "\n",
    "# Load face detection model (using Haar Cascade as fallback)\n",
    "face_cascade = cv2.CascadeClassifier('models/haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Initialize helmet detection model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = vit_b_16(pretrained=False, num_classes=2)\n",
    "\n",
    "# Load trained weights (with error handling)\n",
    "try:\n",
    "    state_dict = torch.load('my_vit_model.pth', map_location=device)\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        if k == 'heads.weight':\n",
    "            k = 'heads.head.weight'\n",
    "        elif k == 'heads.bias':\n",
    "            k = 'heads.head.bias'\n",
    "        new_state_dict[k] = v\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "# Tracking variables\n",
    "last_alert_time = 0\n",
    "tracked_persons = {}\n",
    "\n",
    "def in_entrance_region(box):\n",
    "    x, y, w, h = box\n",
    "    center_x = x + w//2\n",
    "    center_y = y + h//2\n",
    "    return (ENTRANCE_REGION[0] < center_x < ENTRANCE_REGION[2] and \n",
    "            ENTRANCE_REGION[1] < center_y < ENTRANCE_REGION[3])\n",
    "\n",
    "print(\"Starting workplace safety monitoring...\")\n",
    "print(\"Press 'q' to quit\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error reading frame\")\n",
    "        break\n",
    "    \n",
    "    current_time = time.time()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces using Haar Cascade\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE\n",
    "    )\n",
    "    \n",
    "    for (x, y, w, h) in faces:\n",
    "        if not in_entrance_region((x, y, w, h)):\n",
    "            continue\n",
    "            \n",
    "        # Expand to head region\n",
    "        head_y1 = max(0, y - int(h * 0.4))\n",
    "        head_y2 = min(frame.shape[0], y + h + int(h * 0.1))\n",
    "        head_x1 = max(0, x - int(w * 0.3))\n",
    "        head_x2 = min(frame.shape[1], x + w + int(w * 0.3))\n",
    "        \n",
    "        head_roi = frame[head_y1:head_y2, head_x1:head_x2]\n",
    "        if head_roi.size == 0:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Helmet detection\n",
    "            pil_img = Image.fromarray(cv2.cvtColor(head_roi, cv2.COLOR_BGR2RGB))\n",
    "            img_tensor = transform(pil_img).unsqueeze(0).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output = model(img_tensor)\n",
    "                probs = torch.softmax(output, dim=1)\n",
    "            \n",
    "            pred_class = torch.argmax(probs).item()\n",
    "            helmet_confidence = probs[0][pred_class].item()\n",
    "            \n",
    "            if helmet_confidence < MIN_CONFIDENCE:\n",
    "                continue\n",
    "                \n",
    "            # Tracking and visualization\n",
    "            person_id = f\"{x}_{y}\"\n",
    "            color = (0, 255, 0) if pred_class == 1 else (0, 0, 255)\n",
    "            \n",
    "            cv2.rectangle(frame, (head_x1, head_y1), (head_x2, head_y2), color, 2)\n",
    "            label = \"HELMET\" if pred_class == 1 else \"NO HELMET!\"\n",
    "            cv2.putText(frame, f\"{label} {helmet_confidence:.2f}\", \n",
    "                       (head_x1, head_y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "            \n",
    "            # Alert logic\n",
    "            if pred_class == 0 and current_time - last_alert_time > ALERT_COOLDOWN:\n",
    "                if person_id not in tracked_persons or current_time - tracked_persons[person_id] > ALERT_COOLDOWN:\n",
    "                    print(f\"{time.ctime()} - ALERT: Worker without helmet detected!\")\n",
    "                    winsound.Beep(1000, 1000)\n",
    "                    last_alert_time = current_time\n",
    "                    tracked_persons[person_id] = current_time\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Processing error: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Draw monitoring zone\n",
    "    cv2.rectangle(frame, (ENTRANCE_REGION[0], ENTRANCE_REGION[1]), \n",
    "                 (ENTRANCE_REGION[2], ENTRANCE_REGION[3]), (255, 0, 0), 2)\n",
    "    cv2.putText(frame, \"Monitoring Zone\", (ENTRANCE_REGION[0]+10, ENTRANCE_REGION[1]+30), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "    \n",
    "    # Display FPS\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    cv2.putText(frame, f\"FPS: {fps:.1f}\", (10, 30), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "    \n",
    "    cv2.imshow('Workplace Safety Monitoring', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Monitoring stopped\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
